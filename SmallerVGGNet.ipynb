{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steoinnova/steoinnova/blob/main/SmallerVGGNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsOAajtau-hg"
      },
      "outputs": [],
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "#from tensorflow.keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class SmallerVGGNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes, finalAct=\"softmax\"):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(1024))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(finalAct))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "\n",
        "# Define constants\n",
        "DATASET_PATH = '/content/drive/MyDrive/tamil repo'\n",
        "MODEL_PATH = '.'\n",
        "BATCH_SIZE = 200\n",
        "EPOCHS = 200\n",
        "TARGET_WIDTH = 128\n",
        "TARGET_HEIGHT = 128\n",
        "TARGET_DEPTH = 3"
      ],
      "metadata": {
        "id": "4GSUMuQ5gTc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the data generator to flow data from disk\n",
        "print(\"[INFO] Setting up Data Generator...\")\n",
        "data_gen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2)\n",
        "# data_gen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    subset='training',\n",
        "    target_size = (TARGET_WIDTH, TARGET_HEIGHT),\n",
        "    batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "val_generator = data_gen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    subset='validation',\n",
        "    target_size = (TARGET_WIDTH, TARGET_HEIGHT),\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5hQvqEVgXcW",
        "outputId": "c7002bd7-7fa8-47fe-e058-86c7e450d1bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Setting up Data Generator...\n",
            "Found 57 images belonging to 12 classes.\n",
            "Found 9 images belonging to 12 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a33Ln3Pqh5oU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the test dataset\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')\n",
        "\n",
        "# Load the trained DenseNet model\n",
        "model = load_model('smallerVGGNET.')\n",
        "\n",
        "# Apply the DenseNet model to the test dataset\n",
        "predictions = model.predict(test_generator)\n",
        "\n",
        "# Evaluate the performance of the model on the test dataset\n",
        "test_loss, test_acc = model.evaluate(test_generator)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "id": "b2JU09KugXq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BONGiZ0h5c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rslXvbESvDJ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}